# DescripciÃ³n
    Este proyecto integrador forma parte del curso de Data Engineering y tiene como objetivo aplicar los conceptos de procesamiento, transformaciÃ³n y almacenamiento de datos en un entorno prÃ¡ctico.

# Objetivos de la prÃ¡ctica:
Avance 1 â€“ Carga y exploraciÃ³n de datos en SQL

    Realizamos subconsultas relacionadas y no relacionadas, observando su impacto en los tiempos de carga de la base de datos.
    Aplicamos funciones de ventana para analizar datos a nivel de filas con contexto adicional.

Avance 2 â€“ AutomatizaciÃ³n y optimizaciÃ³n de consultas SQL

    Generamos triggers para la manipulaciÃ³n de informaciÃ³n dentro de la base de datos, los cuales nos permiten detectar ciertas acciones generadas.
    Creamos Ã­ndices y analizamos su impacto en los tiempos de ejecuciÃ³n de las consultas.

Avance 3 â€“ TransformaciÃ³n de datos con Python

    Manipulamos datos utilizando la librerÃ­a pandas, e implementamos tÃ©cnicas de limpieza y transformaciÃ³n para preparar los datos.

Estructura de la Carpeta
ğŸ“‚ Proyecto Integrador 1
â”œâ”€â”€ ğŸ“‚ data
â”‚ â”œâ”€â”€ ğŸ“‚ CSV Â # Archivos en formato CSV
â”‚ â”œâ”€â”€ ğŸ“‚ DB_SQL Â # Bases de datos en formato SQL
â”œâ”€â”€ ğŸ“‚ documents Â # DocumentaciÃ³n del proyecto
â”œâ”€â”€ ğŸ“‚ img
â”‚ â”œâ”€â”€ ğŸ“‚ capturas_avance_1 Â # Capturas del avance 1
â”‚ â”œâ”€â”€ ğŸ“‚ capturas_avance_2 Â # Capturas del avance 2
â”œâ”€â”€ ğŸ“‚ sql_scripts Â # Scripts SQL del proyecto
â”‚ â”œâ”€â”€ ğŸ“„ avance_1.sql
â”‚ â”œâ”€â”€ ğŸ“„ avance_2.sql
â”‚ â”œâ”€â”€ ğŸ“„ script_carga_datos.py
â”‚ â”œâ”€â”€ ğŸ“„ script_tablas_pi.sql
â”œâ”€â”€ ğŸ“„ avance_3.ipynb Â # Notebook de pruebas y anÃ¡lisis
â”œâ”€â”€ ğŸ“„ carga_db.ipynb Â # Notebook para carga de datos en la base de datos
â”œâ”€â”€ ğŸ“„ README.md Â # Este archivo README

# Requisitos
Python 3.x
- Pandas, NumPy, SQLAlchemy, matplotlib, seaborn
- Jupyter Notebook
- PostgreSQL / MySQL

# CÃ³mo Ejecutar
- Clonar este repositorio en la mÃ¡quina local.
- Instalar las dependencias con pip install -r requirements.txt.
- Ejecutar los scripts SQL ubicados en sql_scripts/script_tablas_pi.sql para generar la base de datos "sales_company".
- Ejecutar el archivo carga_db.ipynb para realizar la carga de los archivos CSV en la base de datos.

# ConclusiÃ³n
En este proyecto integrador pudimos observar todo el proceso inicial que realiza un Data Engineer, desde la carga hasta la manipulaciÃ³n de los datos.
A lo largo del desarrollo, se implementaron procesos de transformaciÃ³n de datos para asegurar su calidad y estructura Ã³ptima, facilitando su integraciÃ³n en bases de datos SQL.
El uso de herramientas como Python, SQL y Jupyter Notebook permitiÃ³ un enfoque prÃ¡ctico y replicable para el procesamiento de datos.
